{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1ae39ff",
      "metadata": {
        "id": "a1ae39ff"
      },
      "source": [
        "# Object masks from prompts with SAM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a4b25c",
      "metadata": {
        "id": "b4a4b25c"
      },
      "source": [
        "The Segment Anything Model (SAM) predicts object masks given prompts that indicate the desired object. The model first converts the image into an image embedding that allows high quality masks to be efficiently produced from a prompt. \n",
        "\n",
        "The `SamPredictor` class provides an easy interface to the model for prompting the model. It allows the user to first set an image using the `set_image` method, which calculates the necessary image embeddings. Then, prompts can be provided via the `predict` method to efficiently predict masks from those prompts. The model can take as input both point and box prompts, as well as masks from the previous iteration of prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644532a8",
      "metadata": {
        "id": "644532a8"
      },
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07fabfee",
      "metadata": {
        "id": "07fabfee"
      },
      "source": [
        "If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_collab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91dd9a89",
      "metadata": {
        "id": "91dd9a89"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "import sys\n",
        "!{sys.executable} -m pip install opencv-python matplotlib\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "!mkdir images\n",
        "!wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/truck.jpg\n",
        "!wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/groceries.jpg\n",
        "    \n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be845da",
      "metadata": {
        "id": "0be845da"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33681dd1",
      "metadata": {
        "id": "33681dd1"
      },
      "source": [
        "Necessary imports and helper functions for displaying points, boxes, and masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b28288",
      "metadata": {
        "id": "69b28288"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29bc90d5",
      "metadata": {
        "id": "29bc90d5"
      },
      "outputs": [],
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "    \n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
        "    \n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement du modèle"
      ],
      "metadata": {
        "id": "pBSPo31d7ceu"
      },
      "id": "pBSPo31d7ceu"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "PFYYjg7F7ezw"
      },
      "id": "PFYYjg7F7ezw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des données"
      ],
      "metadata": {
        "id": "4aAX4BQB6zh-"
      },
      "id": "4aAX4BQB6zh-"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/axelcarlier/testSA.git"
      ],
      "metadata": {
        "id": "Kxh5HKVN62FP"
      },
      "id": "Kxh5HKVN62FP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/testSA/BD_71/Amegilla quadrifasciata/Amegilla quadrifasciata56044.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "Zb3-uIdJ6-fR"
      },
      "id": "Zb3-uIdJ6-fR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30125fd",
      "metadata": {
        "scrolled": false,
        "id": "e30125fd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "plt.axis('on')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation à partir d'une boîte englobante"
      ],
      "metadata": {
        "id": "DUHPb00p7lqG"
      },
      "id": "DUHPb00p7lqG"
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.set_image(image)"
      ],
      "metadata": {
        "id": "8CFIk1Cb7oVV"
      },
      "id": "8CFIk1Cb7oVV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_box = np.array([185.26785714285714,135.28125,294.64285714285717,224.47767857142858])\n"
      ],
      "metadata": {
        "id": "1zHUxLBI7v_u"
      },
      "id": "1zHUxLBI7v_u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks, _, _ = predictor.predict(\n",
        "    point_coords=None,\n",
        "    point_labels=None,\n",
        "    box=input_box[None, :],\n",
        "    multimask_output=False,\n",
        ")"
      ],
      "metadata": {
        "id": "X5XLgt8u77ZL"
      },
      "id": "X5XLgt8u77ZL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)\n",
        "show_mask(masks[0], plt.gca())\n",
        "show_box(input_box, plt.gca())\n",
        "plt.axis('off')\n",
        "plt.savefig('toto.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HUQoZMHV8mMh"
      },
      "id": "HUQoZMHV8mMh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test avec toutes les images"
      ],
      "metadata": {
        "id": "JRWdxX5Y9Amf"
      },
      "id": "JRWdxX5Y9Amf"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "print('Loading csv file')\n",
        "# Load CSV of classes : #id #path\n",
        "img_boxes = []\n",
        "with open('/content/testSA/filtered_bees.csv', newline='') as csvfile:\n",
        "\tfilereader = csv.reader(csvfile, delimiter=',')\n",
        "\tfor row in filereader:\n",
        "\t\timg_boxes.append(row)"
      ],
      "metadata": {
        "id": "D9MP2Xlt93vL"
      },
      "id": "D9MP2Xlt93vL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_boxes"
      ],
      "metadata": {
        "id": "w6_Lxdkm-Y08"
      },
      "id": "w6_Lxdkm-Y08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img in img_boxes:\n",
        "  path = img[0]\n",
        "  print('testSA/' + path[2:])  \n",
        "  image = cv2.imread('/content/testSA/' + path[2:])\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  input_box = np.array([float(item) for item in img[1:5]])\n",
        "  predictor.set_image(image)\n",
        "  print(input_box)\n",
        "  masks, _, _ = predictor.predict(\n",
        "    point_coords=None,\n",
        "    point_labels=None,\n",
        "    box=input_box[None, :],\n",
        "    multimask_output=False,\n",
        "  )\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.imshow(image)\n",
        "  show_mask(masks[0], plt.gca())\n",
        "  show_box(input_box, plt.gca())\n",
        "  plt.axis('off')\n",
        "  plt.savefig('Results/' + path.split('/')[-1])\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "1jtKm3j--CvD"
      },
      "id": "1jtKm3j--CvD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r abeilles.zip Results"
      ],
      "metadata": {
        "id": "yCPWfQ0zPV5V"
      },
      "id": "yCPWfQ0zPV5V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}